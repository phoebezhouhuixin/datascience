{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "**Base learners** - a model that is slightly better than a coin toss. XGBoost uses decision trees as the base learner. A **decision stump** is a shallow decision tree with little branching."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>Survived</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>26.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Pclass  Sex   Age  Survived\n",
       "0       3    0  22.0         0\n",
       "1       1    1  38.0         1\n",
       "2       3    1  26.0         1\n",
       "3       1    1  35.0         1\n",
       "4       3    0  35.0         0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"data/titanic.csv\")\n",
    "data = data[['Pclass', 'Sex', 'Age', 'Survived']]\n",
    "data['Sex'] = data['Sex'].map({'male': 0, 'female': 1})\n",
    "data = data.dropna()\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 82.68%\n"
     ]
    }
   ],
   "source": [
    "X = data.drop('Survived', axis=1)\n",
    "y = data['Survived']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1)\n",
    "model = XGBClassifier()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "predictions = [round(value) for value in y_pred]\n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scoring XGBoost models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 77.92%\n"
     ]
    }
   ],
   "source": [
    "from numpy import loadtxt\n",
    "\n",
    "dataset = loadtxt('data/pima.txt', delimiter=\",\")\n",
    "X = dataset[:,0:8] \n",
    "Y = dataset[:,8]\n",
    "\n",
    "seed = 7 \n",
    "test_size = 0.30\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=test_size, random_state=seed) \n",
    "\n",
    "model = XGBClassifier() \n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test) \n",
    "predictions = [round(value) for value in y_pred] \n",
    "\n",
    "accuracy = accuracy_score(y_test, predictions) \n",
    "print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Take note that the parameter has been added. The parameter is early_stopping_rounds=36"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-error:0.25974\n",
      "Will train until validation_0-error hasn't improved in 36 rounds.\n",
      "[1]\tvalidation_0-error:0.25974\n",
      "[2]\tvalidation_0-error:0.25974\n",
      "[3]\tvalidation_0-error:0.25974\n",
      "[4]\tvalidation_0-error:0.233766\n",
      "[5]\tvalidation_0-error:0.242424\n",
      "[6]\tvalidation_0-error:0.255411\n",
      "[7]\tvalidation_0-error:0.238095\n",
      "[8]\tvalidation_0-error:0.233766\n",
      "[9]\tvalidation_0-error:0.238095\n",
      "[10]\tvalidation_0-error:0.238095\n",
      "[11]\tvalidation_0-error:0.233766\n",
      "[12]\tvalidation_0-error:0.238095\n",
      "[13]\tvalidation_0-error:0.238095\n",
      "[14]\tvalidation_0-error:0.242424\n",
      "[15]\tvalidation_0-error:0.233766\n",
      "[16]\tvalidation_0-error:0.229437\n",
      "[17]\tvalidation_0-error:0.229437\n",
      "[18]\tvalidation_0-error:0.229437\n",
      "[19]\tvalidation_0-error:0.229437\n",
      "[20]\tvalidation_0-error:0.229437\n",
      "[21]\tvalidation_0-error:0.229437\n",
      "[22]\tvalidation_0-error:0.238095\n",
      "[23]\tvalidation_0-error:0.225108\n",
      "[24]\tvalidation_0-error:0.212121\n",
      "[25]\tvalidation_0-error:0.220779\n",
      "[26]\tvalidation_0-error:0.220779\n",
      "[27]\tvalidation_0-error:0.212121\n",
      "[28]\tvalidation_0-error:0.21645\n",
      "[29]\tvalidation_0-error:0.21645\n",
      "[30]\tvalidation_0-error:0.207792\n",
      "[31]\tvalidation_0-error:0.207792\n",
      "[32]\tvalidation_0-error:0.212121\n",
      "[33]\tvalidation_0-error:0.207792\n",
      "[34]\tvalidation_0-error:0.207792\n",
      "[35]\tvalidation_0-error:0.21645\n",
      "[36]\tvalidation_0-error:0.207792\n",
      "[37]\tvalidation_0-error:0.207792\n",
      "[38]\tvalidation_0-error:0.21645\n",
      "[39]\tvalidation_0-error:0.212121\n",
      "[40]\tvalidation_0-error:0.212121\n",
      "[41]\tvalidation_0-error:0.21645\n",
      "[42]\tvalidation_0-error:0.21645\n",
      "[43]\tvalidation_0-error:0.21645\n",
      "[44]\tvalidation_0-error:0.220779\n",
      "[45]\tvalidation_0-error:0.220779\n",
      "[46]\tvalidation_0-error:0.229437\n",
      "[47]\tvalidation_0-error:0.229437\n",
      "[48]\tvalidation_0-error:0.229437\n",
      "[49]\tvalidation_0-error:0.233766\n",
      "[50]\tvalidation_0-error:0.225108\n",
      "[51]\tvalidation_0-error:0.229437\n",
      "[52]\tvalidation_0-error:0.225108\n",
      "[53]\tvalidation_0-error:0.229437\n",
      "[54]\tvalidation_0-error:0.229437\n",
      "[55]\tvalidation_0-error:0.229437\n",
      "[56]\tvalidation_0-error:0.229437\n",
      "[57]\tvalidation_0-error:0.229437\n",
      "[58]\tvalidation_0-error:0.229437\n",
      "[59]\tvalidation_0-error:0.220779\n",
      "[60]\tvalidation_0-error:0.225108\n",
      "[61]\tvalidation_0-error:0.225108\n",
      "[62]\tvalidation_0-error:0.225108\n",
      "[63]\tvalidation_0-error:0.225108\n",
      "[64]\tvalidation_0-error:0.220779\n",
      "[65]\tvalidation_0-error:0.21645\n",
      "[66]\tvalidation_0-error:0.21645\n",
      "Stopping. Best iteration:\n",
      "[30]\tvalidation_0-error:0.207792\n",
      "\n",
      "Accuracy: 79.22%\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning) \n",
    "\n",
    "eval_set = [(X_test, y_test)] \n",
    "model.fit(X_train, y_train, eval_metric=\"error\",early_stopping_rounds=36, eval_set=eval_set, verbose=True)\n",
    "y_pred = model.predict(X_test) \n",
    "predictions = [round(value) for value in y_pred] \n",
    "\n",
    "accuracy = accuracy_score(y_test, predictions) \n",
    "print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving the trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle \n",
    "\n",
    "pickle.dump(model, open(\"production_pima_model.dat\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 79.22%\n"
     ]
    }
   ],
   "source": [
    "loaded_model = pickle.load(open(\"production_pima_model.dat\", \"rb\")) \n",
    "y_pred = loaded_model.predict(X_test) \n",
    "predictions = [round(value) for value in y_pred]\n",
    "accuracy = accuracy_score(y_test, predictions) \n",
    "print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Selecting features in gradient boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.1030869  0.2586743  0.07711612 0.06305027 0.09934872 0.17890204\n",
      " 0.09226437 0.1275573 ]\n"
     ]
    }
   ],
   "source": [
    "print(model.feature_importances_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot\n",
    "pyplot.bar(range(len(model.feature_importances_)), model.feature_importances_) \n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 0 - Pregnancies: Number of times pregnant\n",
    "- 1 - Glucose: Plasma glucose concentration a 2 hours in an oral glucose tolerance test\n",
    "- 2 - BloodPressure: Diastolic blood pressure (mm Hg)\n",
    "- 3 - SkinThicknessTriceps: Skin fold thickness (mm)\n",
    "- 4 - Insulin: 2-Hour serum insulin (mu U/ml)\n",
    "- 5 - BMIBody: mass index (weight in kg/(height in m)^2)\n",
    "- 6 - DiabetesPedigreeFunctionDiabetes: pedigree function\n",
    "- 7 - AgeAge: (years)\n",
    "- 8 - OutcomeClass: variable (0 or 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=1, gamma=0,\n",
       "              learning_rate=0.1, max_delta_step=0, max_depth=3,\n",
       "              min_child_weight=1, missing=None, n_estimators=100, n_jobs=1,\n",
       "              nthread=None, objective='multi:softprob', random_state=0,\n",
       "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "              silent=None, subsample=1, verbosity=1)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import datasets\n",
    "iris = datasets.load_iris()\n",
    "feat_labels = ['Sepal Length','Sepal Width','Petal Length','Petal Width']\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=0)\n",
    "model = XGBClassifier() \n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Sepal Length', 0.016870115)\n",
      "('Sepal Width', 0.02123037)\n",
      "('Petal Length', 0.7144931)\n",
      "('Petal Width', 0.24740641)\n"
     ]
    }
   ],
   "source": [
    "# Print the name and gini importance of each feature\n",
    "for feature in zip(feat_labels, model.feature_importances_):\n",
    "    print(feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectFromModel\n",
    "\n",
    "sfm = SelectFromModel(model, threshold=0.25)\n",
    "sfm.fit(X_train, y_train)\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Petal Length\n"
     ]
    }
   ],
   "source": [
    "for feature_list_index in sfm.get_support(indices=True):\n",
    "    print(feat_labels[feature_list_index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=1, gamma=0,\n",
       "              learning_rate=0.1, max_delta_step=0, max_depth=3,\n",
       "              min_child_weight=1, missing=None, n_estimators=100, n_jobs=1,\n",
       "              nthread=None, objective='multi:softprob', random_state=0,\n",
       "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "              silent=None, subsample=1, verbosity=1)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_important_train = sfm.transform(X_train)\n",
    "X_important_test = sfm.transform(X_test)\n",
    "\n",
    "clf_important = XGBClassifier()\n",
    "clf_important.fit(X_important_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
